{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also certain attributes of each prouct and store have been defined. The aim is **to build a predictive model and predict the sales of each product at a particular outlet.**\n",
    "\n",
    "- And using this model, we will try to understand the properties of products and oulets which play a key role in increasing sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We will explore the problem in following stages:__\n",
    "\n",
    "- __Hypothesis Generation :__ understanding the problem better by brainstorming possible factors that can impact the outcome\n",
    "\n",
    "- __Data Exploration :__ looking at categorical and continuous feature summaries and making inferences about the data.\n",
    "\n",
    "- __Data Cleaning :__ imputing missing values in the data and checking for outliers\n",
    "\n",
    "- __Feature Engineering :__ modifying existing variables and creating new ones for analysis\n",
    "\n",
    "- __Model Building :__ making predictive models on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Hypothesis Generation \n",
    "\n",
    "- Before looking at the data we try to understand the problem and making some hypothesis about what could potentially have a good impact on the outcome. \n",
    "\n",
    "     ### Problem Statement \n",
    " \n",
    "\n",
    "- BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also certain attributes of each prouct and store have been defined. The aim is **to build a predictive model and predict the sales of each product at a particular outlet.**\n",
    "\n",
    "\n",
    "- And using this model, we will try to understand the properties of products and outlets which play a key role in increasing sales.\n",
    "\n",
    "- So, we should find out the properties of a product and store which impacts the sales of a product.\n",
    "\n",
    "     ### The Hypotheses \n",
    "\n",
    "\n",
    "- Some hypothesis examples : \n",
    "\n",
    "#### Store Level Hypotheses: \n",
    "\n",
    "\n",
    "\n",
    "__City type:__ Stores located in urban or Tier 1 cities should have higher sales because of the higher income levels of people there.\n",
    "\n",
    "__Population Density:__ Stores located in densely populated areas should have higher sales because of more demand.\n",
    "\n",
    "__Store Capacity:__ Stores which are very big in size should have higher sales as they act like one-stop-shops and people would prefer getting everything from one place\n",
    "\n",
    "__Competitors:__ Stores having similar establishments nearby should have less sales because of more competition.\n",
    "\n",
    "__Marketing:__ Stores which have a good marketing division should have higher sales as it will be able to attract customers through the right offers and advertising.\n",
    "\n",
    "__Location:__ Stores located within popular marketplaces should have higher sales because of better access to customers.\n",
    "\n",
    "__Customer Behavior:__ Stores keeping the right set of products to meet the local needs of customers will have higher sales.\n",
    "\n",
    "__Ambiance:__ Stores which are well-maintained and managed by polite and humble people are expected to have higher footfall and thus higher sales.\n",
    "\n",
    "#### Product Level Hypotheses: \n",
    "\n",
    "\n",
    "\n",
    "__Brand:__ Branded products should have higher sales because of higher trust in the customer.\n",
    "\n",
    "__Packaging:__ Products with good packaging can attract customers and sell more.\n",
    "\n",
    "__Utility:__ Daily use products should have a higher tendency to sell as compared to the specific use products.\n",
    "\n",
    "__Display Area:__ Products which are given bigger shelves in the store are likely to catch attention first and sell more.\n",
    "\n",
    "__Visibility in Store:__ The location of product in a store will impact sales. Ones which are right at entrance will catch the eye of customer first rather than the ones in back.\n",
    "\n",
    "__Advertising:__ Better advertising of products in the store will should higher sales in most cases.\n",
    "\n",
    "__Promotional Offers:__ Products accompanied with attractive offers and discounts will sell more.\n",
    "\n",
    "\n",
    "__NOTE:__ We can also make any others hypothesis. We will try to find answers to these hypothesis as data allow this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration \n",
    "\n",
    "<img src=\"Data Dictionary.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a copy of the data \n",
    "train_original = train.copy()\n",
    "test_original = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Its generally a good idea to combine both train and test data sets into one, perform feature engineering and then divide them later again. This saves the trouble of performing the same steps twice on test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"source\"] = 'train'\n",
    "test['source'] = 'test'\n",
    "\n",
    "data = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8523, 13) (5681, 12) (14204, 13)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                  2439\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  4016\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales            5681\n",
       "source                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the null values \n",
    "\n",
    "data.apply(lambda x: sum(x.isnull())) # data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Item_Outlet_Sales is the target variable and missing values are ones in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11765.000000</td>\n",
       "      <td>14204.000000</td>\n",
       "      <td>14204.000000</td>\n",
       "      <td>14204.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.792854</td>\n",
       "      <td>0.065953</td>\n",
       "      <td>141.004977</td>\n",
       "      <td>1997.830681</td>\n",
       "      <td>2181.288914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.652502</td>\n",
       "      <td>0.051459</td>\n",
       "      <td>62.086938</td>\n",
       "      <td>8.371664</td>\n",
       "      <td>1706.499616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.555000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.290000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>33.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.710000</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>94.012000</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>834.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.054021</td>\n",
       "      <td>142.247000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1794.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.750000</td>\n",
       "      <td>0.094037</td>\n",
       "      <td>185.855600</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>3101.296400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.350000</td>\n",
       "      <td>0.328391</td>\n",
       "      <td>266.888400</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>13086.964800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Item_Weight  Item_Visibility      Item_MRP  Outlet_Establishment_Year  \\\n",
       "count  11765.000000     14204.000000  14204.000000               14204.000000   \n",
       "mean      12.792854         0.065953    141.004977                1997.830681   \n",
       "std        4.652502         0.051459     62.086938                   8.371664   \n",
       "min        4.555000         0.000000     31.290000                1985.000000   \n",
       "25%        8.710000         0.027036     94.012000                1987.000000   \n",
       "50%       12.600000         0.054021    142.247000                1999.000000   \n",
       "75%       16.750000         0.094037    185.855600                2004.000000   \n",
       "max       21.350000         0.328391    266.888400                2009.000000   \n",
       "\n",
       "       Item_Outlet_Sales  \n",
       "count        8523.000000  \n",
       "mean         2181.288914  \n",
       "std          1706.499616  \n",
       "min            33.290000  \n",
       "25%           834.247400  \n",
       "50%          1794.331000  \n",
       "75%          3101.296400  \n",
       "max         13086.964800  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at some basic statistics for numerical variables\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Item_Visibility** has a min value of zero. This makes no practical\n",
    "\n",
    "- **Outlet_Establishment_Years** vary from 1985 to 2009. The values might not be apt in this form. Rather, if we can convert them to how old the particular store is, it should be have a better impact on sales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier               1559\n",
       "Item_Weight                    416\n",
       "Item_Fat_Content                 5\n",
       "Item_Visibility              13006\n",
       "Item_Type                       16\n",
       "Item_MRP                      8052\n",
       "Outlet_Identifier               10\n",
       "Outlet_Establishment_Year        9\n",
       "Outlet_Size                      4\n",
       "Outlet_Location_Type             3\n",
       "Outlet_Type                      4\n",
       "Item_Outlet_Sales             3494\n",
       "source                           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the categorical variables \n",
    "\n",
    "data.apply(lambda x : len(x.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So, we can see that there are __1559 products and 10 outlets.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Item_Identifier',\n",
       " 'Item_Fat_Content',\n",
       " 'Item_Type',\n",
       " 'Outlet_Identifier',\n",
       " 'Outlet_Size',\n",
       " 'Outlet_Location_Type',\n",
       " 'Outlet_Type',\n",
       " 'source']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = [x for x in data.columns if data.dtypes[x]=='object']\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency of Categories for variables Item_Fat_Content\n",
      "Low Fat    8485\n",
      "Regular    4824\n",
      "LF          522\n",
      "reg         195\n",
      "low fat     178\n",
      "Name: Item_Fat_Content, dtype: int64\n",
      "\n",
      "Frequency of Categories for variables Item_Type\n",
      "Fruits and Vegetables    2013\n",
      "Snack Foods              1989\n",
      "Household                1548\n",
      "Frozen Foods             1426\n",
      "Dairy                    1136\n",
      "Baking Goods             1086\n",
      "Canned                   1084\n",
      "Health and Hygiene        858\n",
      "Meat                      736\n",
      "Soft Drinks               726\n",
      "Breads                    416\n",
      "Hard Drinks               362\n",
      "Others                    280\n",
      "Starchy Foods             269\n",
      "Breakfast                 186\n",
      "Seafood                    89\n",
      "Name: Item_Type, dtype: int64\n",
      "\n",
      "Frequency of Categories for variables Outlet_Size\n",
      "Medium    4655\n",
      "Small     3980\n",
      "High      1553\n",
      "Name: Outlet_Size, dtype: int64\n",
      "\n",
      "Frequency of Categories for variables Outlet_Location_Type\n",
      "Tier 3    5583\n",
      "Tier 2    4641\n",
      "Tier 1    3980\n",
      "Name: Outlet_Location_Type, dtype: int64\n",
      "\n",
      "Frequency of Categories for variables Outlet_Type\n",
      "Supermarket Type1    9294\n",
      "Grocery Store        1805\n",
      "Supermarket Type3    1559\n",
      "Supermarket Type2    1546\n",
      "Name: Outlet_Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's explore further using the freauency of different categories in each nominal variables.\n",
    "\n",
    "# Filter categorical variables\n",
    "\n",
    "categ_columns = [x for x in data.dtypes.index if data.dtypes[x]=='object']\n",
    "\n",
    "# Exclude ID cols and source\n",
    "\n",
    "categ_columns = [x for x in categ_columns if x not in ['Item_Identifier','Outlet_Identifier', 'source' ]]\n",
    "\n",
    "# print Frequency of categories \n",
    "\n",
    "for col in categ_columns :\n",
    "    print('\\nFrequency of Categories for variables',col)\n",
    "    print(data[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output gives us following observations:\n",
    "\n",
    "- __Item_Fat_Content:__ Some of ‘Low Fat’ values mis-coded as ‘low fat’ and ‘LF’. Also, some of ‘Regular’ are mentioned as ‘regular’.\n",
    "\n",
    "- __Item_Type:__ Not all categories have substantial numbers. It looks like combining them can give better results.\n",
    "\n",
    "- __Outlet_Type:__ Supermarket Type2 and Type3 can be combined. But we should check if that’s a good idea before doing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This step typically involves imputing missing values and treating outliers. Though outlier removal is very important in regression techniques, advanced tree based algorithms are impervious to outliers.So we will focus on the imputation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Item_Weight'].fillna(data['Item_Weight'].mean(), inplace=True)\n",
    "data['Outlet_Size'].fillna(data['Outlet_Size'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                     0\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                     0\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales            5681\n",
       "source                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We explored some nuances in the data in the data exploration section.Let's resolve them.\n",
    "\n",
    "- We also create some new variables using the existing ones in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Condider combining Outlet_Type__\n",
    "\n",
    "During exploration, we decided to consider combining the Supermarket Type2 and Type3 variables.But is that a good idea? A quick way to check that could be to analyze the mean sales by type of store. If they have similar sales, then keeping them separate won’t help much.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Grocery Store</th>\n",
       "      <td>339.828500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supermarket Type1</th>\n",
       "      <td>2316.181148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supermarket Type2</th>\n",
       "      <td>1995.498739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supermarket Type3</th>\n",
       "      <td>3694.038558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Item_Outlet_Sales\n",
       "Outlet_Type                         \n",
       "Grocery Store             339.828500\n",
       "Supermarket Type1        2316.181148\n",
       "Supermarket Type2        1995.498739\n",
       "Supermarket Type3        3694.038558"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pivot_table(values='Item_Outlet_Sales',index='Outlet_Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This shows significant difference between them and we’ll leave them as it is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Modify Item_Visibility__ \n",
    "\n",
    "We noticed that the minimum value here is 0, which makes no practical sense. Lets consider it like missing information and impute it with mean visibility of that product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Item_Visibility'].replace(0, data['Item_Visibility'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003574698"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Item_Visibility'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Create a broad category of Type of Item__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>Dairy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>Soft Drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>Meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>Household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FDP36</td>\n",
       "      <td>Baking Goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FDO10</td>\n",
       "      <td>Snack Foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FDP10</td>\n",
       "      <td>Snack Foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FDH17</td>\n",
       "      <td>Frozen Foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FDU28</td>\n",
       "      <td>Frozen Foods</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier              Item_Type\n",
       "0           FDA15                  Dairy\n",
       "1           DRC01            Soft Drinks\n",
       "2           FDN15                   Meat\n",
       "3           FDX07  Fruits and Vegetables\n",
       "4           NCD19              Household\n",
       "5           FDP36           Baking Goods\n",
       "6           FDO10            Snack Foods\n",
       "7           FDP10            Snack Foods\n",
       "8           FDH17           Frozen Foods\n",
       "9           FDU28           Frozen Foods"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Item_Identifier', 'Item_Type']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Item_Type__ variable has 16 categories which might prove to be very useful in analysis. So its a good idea to combine them. \n",
    "If you look at the Item_Identifier, i.e. the unique ID of each item, it starts with either FD, DR or NC. If you see the categories, these look like being Food, Drinks and Non-Consumables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Food              10201\n",
       "Non-Consumable     2686\n",
       "Drinks             1317\n",
       "Name: Item_Type_Combined, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first two characters of ID \n",
    "data['Item_Type_Combined'] = data['Item_Identifier'].apply(lambda x: x[0:2])\n",
    "\n",
    "# Rename them to more intuitive categories \n",
    "data['Item_Type_Combined'] = data['Item_Type_Combined'].map({ 'FD':'Food',\n",
    "                                                               'NC':'Non-Consumable',\n",
    "                                                                'DR':'Drinks' })\n",
    " \n",
    "data['Item_Type_Combined'].value_counts()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Determine the years of operation of a store__\n",
    "\n",
    "- Let's make a new column depicting the years of operation of a store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14\n",
       "1     4\n",
       "2    14\n",
       "3    15\n",
       "4    26\n",
       "Name: Outlet_Years, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Outlet_Years'] = 2013 - data['Outlet_Establishment_Year']\n",
    "data['Outlet_Years'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Modify categories of Item_Fat_Content__ \n",
    "\n",
    "- We found typos and difference in representation in categories of Item_Fat_Content variable.\n",
    "\n",
    "\n",
    "'Low fat, Regular, LF, reg, low fat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat    9185\n",
       "Regular    5019\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Item_Fat_Content'] = data['Item_Fat_Content'].replace({'LF': 'Low Fat',\n",
    "                                                            'reg': 'Regular',\n",
    "                                                            'low fat': 'Low Fat'})\n",
    "data['Item_Fat_Content'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It makes more sense. But in step 4 we saw there were some non-consumables, a fat content should not be specified for them.\n",
    "- Let's creat a separet category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat       6499\n",
       "Regular       5019\n",
       "Non-Edible    2686\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Item_Type_Combined']=='Non-Consumable', 'Item_Fat_Content'] = 'Non-Edible'\n",
    "data['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6. Numerical and One-Hot Coding of Categorical Variables__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since scikit-learn accepts only numerical variables, We will convert all categories of nominal variables into numeric types. \n",
    "- Also, I wanted Outlet_Identifier as a variable as well. So I created a new variable ‘Outlet’ same as Outlet_Identifier and coded that. Outlet_Identifier should remain as it is, because it will be required in the submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['Outlet'] = le.fit_transform(data['Outlet_Identifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_mod = ['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Item_Type_Combined','Outlet_Type','Outlet']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    data[i] = le.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__One Hot Coding__\n",
    "\n",
    "It refers to creating dummy variables, one for each category of a categorical variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=var_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier               object\n",
       "Item_Weight                  float64\n",
       "Item_Visibility              float64\n",
       "Item_Type                     object\n",
       "Item_MRP                     float64\n",
       "Outlet_Identifier             object\n",
       "Outlet_Establishment_Year      int64\n",
       "Item_Outlet_Sales            float64\n",
       "source                        object\n",
       "Outlet_Years                   int64\n",
       "Item_Fat_Content_0             uint8\n",
       "Item_Fat_Content_1             uint8\n",
       "Item_Fat_Content_2             uint8\n",
       "Outlet_Location_Type_0         uint8\n",
       "Outlet_Location_Type_1         uint8\n",
       "Outlet_Location_Type_2         uint8\n",
       "Outlet_Size_0                  uint8\n",
       "Outlet_Size_1                  uint8\n",
       "Outlet_Size_2                  uint8\n",
       "Item_Type_Combined_0           uint8\n",
       "Item_Type_Combined_1           uint8\n",
       "Item_Type_Combined_2           uint8\n",
       "Outlet_Type_0                  uint8\n",
       "Outlet_Type_1                  uint8\n",
       "Outlet_Type_2                  uint8\n",
       "Outlet_Type_3                  uint8\n",
       "Outlet_0                       uint8\n",
       "Outlet_1                       uint8\n",
       "Outlet_2                       uint8\n",
       "Outlet_3                       uint8\n",
       "Outlet_4                       uint8\n",
       "Outlet_5                       uint8\n",
       "Outlet_6                       uint8\n",
       "Outlet_7                       uint8\n",
       "Outlet_8                       uint8\n",
       "Outlet_9                       uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exporting Data__\n",
    "- convert data back into train and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kty\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "#Drop the columns which have been converted to different types:\n",
    "data.drop(['Item_Type','Outlet_Establishment_Year'],axis=1,inplace=True)\n",
    "\n",
    "# Divide into test and train datasets \n",
    "train = data.loc[data['source'] == 'train']\n",
    "test = data.loc[data['source'] == 'test']\n",
    "\n",
    "# Drop unnecesary columns \n",
    "test.drop(['source', 'Item_Outlet_Sales'], axis=1, inplace=True)\n",
    "train.drop(['source'], axis=1, inplace=True)\n",
    "\n",
    "# Drop column that has not any effect on 'Item_Outlet_Sales'\n",
    "train = train.drop(['Item_Identifier', 'Outlet_Identifier'], axis=1)\n",
    "test = test.drop(['Item_Identifier', 'Outlet_Identifier'], axis=1)\n",
    "\n",
    "#Export files as modified vrsions \n",
    "train.to_csv(\"train_modified.csv\", index=False)\n",
    "test.to_csv(\"test_modified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = pd.read_csv('train_modified.csv')\n",
    "dtest = pd.read_csv('test_modified.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8523, 31) (5681, 30)\n"
     ]
    }
   ],
   "source": [
    "print(dtrain.shape, dtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make prediction firstly using just train dataset, \n",
    "# We divide train dataset into two part train and validation\n",
    "\n",
    "X = dtrain.drop('Item_Outlet_Sales', axis=1)\n",
    "y = dtrain.Item_Outlet_Sales\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5794373737992737"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model and pediction \n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred_val = model.predict(x_val)\n",
    "\n",
    "model.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make prediction for the test dataset\n",
    "\n",
    "pred_test= model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import submission file to submit our result\n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# We need the 'Item_Identifier', 'Outlet_Identifier' and 'Item_Outlet_Sales' columns \n",
    "\n",
    "submission['Item_Outlet_Sales'] = pred_test \n",
    "submission['Item_Identifier'] = test_original['Item_Identifier']\n",
    "submission['Outlet_Identifier'] = test_original['Outlet_Identifier']\n",
    "\n",
    "submission['Item_Outlet_Sales'] = abs(submission['Item_Outlet_Sales'])\n",
    "\n",
    "# Finally we will convert submission to csv file to submitand check the accuracy \n",
    "\n",
    "pd.DataFrame(submission, columns=['Item_Identifier','Outlet_Identifier','Item_Outlet_Sales']).to_csv('submission_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
